{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482150cd",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0139db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lib.data\n",
    "import lib.models\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42b7164",
   "metadata": {},
   "source": [
    "# Algorithm setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1056c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accs = []\n",
    "seeds = range(20)\n",
    "\n",
    "# data parameters\n",
    "data_name = \"vehicle\"\n",
    "data_path=os.path.expanduser('data')\n",
    "\n",
    "# label noise parameters\n",
    "flip_labels = False\n",
    "eta = 0.0\n",
    "\n",
    "# network architecture\n",
    "dimh = 2\n",
    "depth = 4\n",
    "blocks = 2\n",
    "\n",
    "# optimiser parameters\n",
    "lr = 0.01\n",
    "gamma_cycle = 4\n",
    "weight_decay = 0.01\n",
    "num_epochs = 240\n",
    "batch_size_train = 64\n",
    "batch_size_test = 64\n",
    "categorical_loss = torch.nn.NLLLoss(reduction=\"mean\")\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# training options\n",
    "train_kwargs = {\"batch_size\": batch_size_train, \"shuffle\": True}\n",
    "test_kwargs = {\"batch_size\": batch_size_test, \"shuffle\": True}\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# load data and retrieve input feature dimension\n",
    "X, Y = lib.data.load_libsvm(data_path, data_name)\n",
    "d = X.shape[1]\n",
    "K = np.max(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a637f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct correct 77.65\n",
      "pct correct 78.24\n",
      "pct correct 81.76\n",
      "pct correct 80.59\n",
      "pct correct 77.65\n",
      "pct correct 73.53\n",
      "pct correct 78.82\n",
      "pct correct 80.59\n",
      "pct correct 75.29\n",
      "pct correct 71.18\n",
      "pct correct 78.82\n",
      "pct correct 76.47\n",
      "pct correct 76.47\n",
      "pct correct 77.06\n",
      "pct correct 75.88\n",
      "pct correct 75.88\n",
      "pct correct 75.29\n",
      "pct correct 71.18\n",
      "pct correct 80.59\n",
      "pct correct 75.29\n"
     ]
    }
   ],
   "source": [
    "for seed in seeds:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
    "        X, Y, test_size=0.2, random_state=seed\n",
    "    )\n",
    "\n",
    "    # initialise models and attach processed data to main model\n",
    "    inner_model = lib.models.MultinomialLogisticRegression(\n",
    "        input_dim=d, output_dim=K\n",
    "    )\n",
    "    link_model = lib.models.LegendreLink(\n",
    "        n_blocks=blocks, K=K, dim_hidden=dimh, depth=depth\n",
    "    )\n",
    "\n",
    "    if cuda:\n",
    "        inner_model = inner_model.cuda()\n",
    "        link_model = link_model.cuda()\n",
    "        cuda_kwargs = {\"num_workers\": 4, \"pin_memory\": True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    if flip_labels:\n",
    "        Ytrain = lib.data.noisify(Ytrain, K=K, eta=eta, random_state=seed)\n",
    "\n",
    "    data_train = lib.data.LibSVMDataset(Xtrain, Ytrain)\n",
    "    data_test = lib.data.LibSVMDataset(Xtest, Ytest)\n",
    "    train_loader = DataLoader(data_train, **train_kwargs)\n",
    "    test_loader = DataLoader(data_test, **test_kwargs)\n",
    "    \n",
    "    model_parameters = list(inner_model.parameters()) + list(link_model.parameters())\n",
    "    opt = torch.optim.Adam(model_parameters, lr=lr)\n",
    "    sch = torch.optim.lr_scheduler.StepLR(opt, step_size=gamma_cycle * len(train_loader), gamma=0.95)\n",
    "    \n",
    "    for e in range(1, num_epochs + 1):\n",
    "        # optimization step\n",
    "        inner_model.train()\n",
    "        link_model.train()\n",
    "        for X_train, Y_train in train_loader:\n",
    "            if cuda:\n",
    "                X_train, Y_train = X_train.cuda(), Y_train.cuda()\n",
    "            X_train, Y_train = X_train.type(torch.double), Y_train.flatten().type(\n",
    "                torch.long\n",
    "            )\n",
    "            opt.zero_grad()\n",
    "            logp_pred = link_model(inner_model(X_train), context=None)\n",
    "            loss_train = categorical_loss(logp_pred, Y_train)\n",
    "\n",
    "            # L2 regularisation on all parameters\n",
    "            regulariser = torch.sum(torch.zeros(1, dtype=torch.float))\n",
    "            for p in model_parameters:\n",
    "                regulariser = regulariser + torch.sum(p**2)\n",
    "\n",
    "            if cuda:\n",
    "                loss_train = loss_train.cuda()\n",
    "                regulariser = regulariser.cuda()\n",
    "\n",
    "            regularised_loss = loss_train + 0.5 * weight_decay * regulariser\n",
    "\n",
    "            regularised_loss.backward()\n",
    "            opt.step()\n",
    "            sch.step()\n",
    "        \n",
    "    inner_model.eval()\n",
    "    link_model.eval()\n",
    "    # print step\n",
    "    y_true_test, logp_pred_test, y_pred_test = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for X_test, Y_test in test_loader:  # testing data\n",
    "            if cuda:\n",
    "                X_test, Y_test = X_test.cuda(), Y_test.flatten().cuda()\n",
    "            X_test, Y_test = X_test.type(\n",
    "                torch.double\n",
    "            ), Y_test.flatten().type(torch.long)\n",
    "            logp_pred = link_model(inner_model(X_test), context=None)\n",
    "            Y_pred = logp_pred.argmax(dim=-1)\n",
    "\n",
    "            y_true_test.extend(Y_test.flatten().tolist())\n",
    "            logp_pred_test.extend(logp_pred.tolist())\n",
    "            y_pred_test.extend(Y_pred.flatten().tolist())\n",
    "\n",
    "        y_true_test, logp_pred_test, y_pred_test = (\n",
    "            torch.as_tensor(y_true_test),\n",
    "            torch.as_tensor(logp_pred_test),\n",
    "            torch.as_tensor(y_pred_test),\n",
    "        )\n",
    "        prop_correct_test = (\n",
    "            torch.sum(y_pred_test == y_true_test) / y_pred_test.shape[0]\n",
    "        )\n",
    "    print(f\"pct correct {100 * prop_correct_test:2.2f}\")\n",
    "    test_accs.append(100 * prop_correct_test.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383207f9",
   "metadata": {},
   "source": [
    "# Accuracy statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "011dbb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.91176470588235"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean test accuracy\n",
    "np.mean(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7958be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6526287150171274"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# std error\n",
    "np.std(test_accs, ddof=1)/np.sqrt(len(test_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82793aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
